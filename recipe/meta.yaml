{% set name = "optimum" %}
{% set version = "1.13.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/optimum-{{ version }}.tar.gz
  sha256: a637ce85881019333f40f19ae7ee8ae9e22e2346cdd4f25b9b07be3a95ca4962

build:
  number: 0
  noarch: python
  script: "{{ PYTHON }} -m pip install . -vv"
  entry_points:
    - optimum-cli = optimum.commands.optimum_cli:main

requirements:
  host:
    - pip
    - python >=3.7
  run:
    - python >=3.7
    - coloredlogs
    - sympy
    - transformers >=4.26.0
    - sentencepiece >=0.1.91 # dependency of transformers(sentencepiece)
    - protobuf # dependency of transformers(sentencepiece)
    - packaging
    - pytorch >=1.9
    - numpy
    - huggingface_hub >=0.8.0
    - datasets

test:
  imports:
    - optimum
  commands:
    - pip check
    - optimum-cli --help
  requires:
    - pip

about:
  home: https://huggingface.co/hardware
  summary: |
    Optimum Library is an extension of the Hugging Face Transformers 
    library, providing a framework to integrate third-party libraries 
    from Hardware Partners and interface with their specific functionality.
  license: Apache-2.0
  license_file: LICENSE
  description: |
    ðŸ¤— Optimum is an extension of ðŸ¤— Transformers, providing a set of performance 
    optimization tools enabling maximum efficiency to train and run models on 
    targeted hardware.

    The AI ecosystem evolves quickly and more and more specialized hardware along 
    with their own optimizations are emerging every day. As such, Optimum enables 
    users to efficiently use any of these platforms with the same ease inherent 
    to transformers.

    PyPI: [https://pypi.org/project/optimum/](https://pypi.org/project/optimum/)

  doc_url: https://huggingface.co/docs/optimum/
  dev_url: https://github.com/huggingface/optimum

extra:
  recipe-maintainers:
    - ilya-lavrenov
    - sugatoray
