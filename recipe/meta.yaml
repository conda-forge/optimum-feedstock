{% set name = "optimum" %}
{% set version = "1.26.1" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/optimum-{{ version }}.tar.gz
  sha256: bc42f5f2394a395862d015af583120f5a076fd33ee3390d1f4e9db1ce47de5b8

build:
  number: 0
  noarch: python
  script: "{{ PYTHON }} -m pip install . -vv"
  entry_points:
    - optimum-cli = optimum.commands.optimum_cli:main

requirements:
  host:
    - pip
    - setuptools
    - python {{ python_min }}
  run:
    - python >={{ python_min }}
    - transformers >=4.29.0
    - sentencepiece >=0.1.91,!=0.1.92 # dependency of transformers(sentencepiece)
    - protobuf # dependency of transformers(sentencepiece)
    - packaging
    - pytorch >=1.11
    - numpy
    - huggingface_hub >=0.8.0

test:
  imports:
    - optimum
  commands:
    - pip check
    - optimum-cli --help
  requires:
    - pip
    - python {{ python_min }}

about:
  home: https://huggingface.co/hardware
  summary: |
    Optimum Library is an extension of the Hugging Face Transformers 
    library, providing a framework to integrate third-party libraries 
    from Hardware Partners and interface with their specific functionality.
  license: Apache-2.0
  license_file: LICENSE
  description: |
    ðŸ¤— Optimum is an extension of ðŸ¤— Transformers, providing a set of performance 
    optimization tools enabling maximum efficiency to train and run models on 
    targeted hardware.

    The AI ecosystem evolves quickly and more and more specialized hardware along 
    with their own optimizations are emerging every day. As such, Optimum enables 
    users to efficiently use any of these platforms with the same ease inherent 
    to transformers.

    PyPI: [https://pypi.org/project/optimum/](https://pypi.org/project/optimum/)

  doc_url: https://huggingface.co/docs/optimum/
  dev_url: https://github.com/huggingface/optimum

extra:
  recipe-maintainers:
    - ilya-lavrenov
    - sugatoray
    - shermansiu
