{% set name = "optimum" %}
{% set version = "1.16.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/optimum-{{ version }}.tar.gz
  sha256: 0ac278c94b94888ea3b68f6a426c836900621d29db1d176587a584fd43600ba9

build:
  number: 0
  noarch: python
  script: "{{ PYTHON }} -m pip install . -vv"
  entry_points:
    - optimum-cli = optimum.commands.optimum_cli:main

requirements:
  host:
    - pip
    - python >=3.7
  run:
    - python >=3.7
    - coloredlogs
    - sympy
    - transformers >=4.26.0
    - sentencepiece >=0.1.91 # dependency of transformers(sentencepiece)
    - protobuf # dependency of transformers(sentencepiece)
    - packaging
    - pytorch >=1.9
    - numpy
    - huggingface_hub >=0.8.0
    - datasets

test:
  imports:
    - optimum
  commands:
    - pip check
    - optimum-cli --help
  requires:
    - pip

about:
  home: https://huggingface.co/hardware
  summary: |
    Optimum Library is an extension of the Hugging Face Transformers 
    library, providing a framework to integrate third-party libraries 
    from Hardware Partners and interface with their specific functionality.
  license: Apache-2.0
  license_file: LICENSE
  description: |
    ðŸ¤— Optimum is an extension of ðŸ¤— Transformers, providing a set of performance 
    optimization tools enabling maximum efficiency to train and run models on 
    targeted hardware.

    The AI ecosystem evolves quickly and more and more specialized hardware along 
    with their own optimizations are emerging every day. As such, Optimum enables 
    users to efficiently use any of these platforms with the same ease inherent 
    to transformers.

    PyPI: [https://pypi.org/project/optimum/](https://pypi.org/project/optimum/)

  doc_url: https://huggingface.co/docs/optimum/
  dev_url: https://github.com/huggingface/optimum

extra:
  recipe-maintainers:
    - ilya-lavrenov
    - sugatoray
